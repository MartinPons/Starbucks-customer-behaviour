from sklearn.model_selection import train_test_split
from sklearn.metrics import  classification_report, confusion_matrix
import statsmodels.api as sm
import patsy
import itertools
import pandas as pd
import numpy as np


def pretty_coefficients(summary, exog_df):

    '''Reformulates the summary function from a logistic model: removes confidence interval columns, z values
    add ads odd-ratio columns. Also cleans the variable names so they are more readable


    INPUTS

        - summary (statsmodels.iolib.summary.Summary): a summmary instance generated by a logistic model using the statsmodels package
        - exog_df (DesignMatrix): matrix with the exogenous variables generated with the ptasy package

    RETURNS

        A DataFrame with the reformatted logistic model coefficients.
    '''

    # get the table from the summary obect
    summary_df = pd.DataFrame(summary.tables[1].data[1:], columns = summary.tables[1].data[0])
    summary_df.rename(columns = {'': "Variable"}, inplace = True)
    summary_df['Variable'] = exog_df.design_info.column_names

    # clean variable names
    summary_df["Variable"] = summary_df.Variable.apply \
        (lambda x: x.replace("C(offer_type, Treatment('Informational'))", ""))

    # remove columns
    summary_df.drop(["std err", "[0.025", "0.975]"], axis = 1, inplace = True)

    summary_df['coef'] = summary_df.coef.astype('float')

    # generate Odds ratio measure
    summary_df["odds ratio"] = summary_df.coef.apply(lambda x: np.exp(x))
    summary_df[["coef", "odds ratio"]] = summary_df[["coef", "odds ratio"]].round(3)

    summary_df = summary_df.reindex(columns = ['Variable', 'coef', 'odds ratio' , 'z', 'P>|z|'])

    return summary_df


def expand_grid(*args, var_names):

    """
    Takes any number of iterables as arguments
    and returns a data frame with the cartessian product.

    INPUTS

     - *args: a number of iterables from which values are crossed
     - var_names: the column names for the DataFrame generated

     RETURNS

         A DataFrame in which the rows contain every single combination of values resulting crossing the iterables in *args
    """

    return pd.DataFrame(columns = var_names, data = list(itertools.product(*args)))



def fit_logistic(offers, model_vars, interaction = False):

    '''Fits a logistic regression for the offers dataframe, having "completed" as dependent variable and
    "offer_type" as one of its independent variables. It deals with the data preparation including
    separating training and test set, and write a formula for fitting the model.

    INPUTS

        - offers (DataFrame): data with the offers
        - model_vars (list): variable names from the offers dataset, excluding offer_type, that serve as the indep. variables
        - ineraction (bool): flag indicating if the model to be fit includes interaction terms for offer type

    RETURNS

        - result : fitted logistic regression model for the offers dataset, fitted with the statsmodel package
        - forula: a string with the formula containing the independent variables from the model
        - exog_val: DesignMatrix from the patsy package with the data form the independent variables
        - X_val: DataFrame for the independent variables from the validation set
        - y_val: array for the "completed" variable, our dependent variable in the model

    '''

    # sets Informational as base category for offer_type
    base_category = 'Informational'
    offer_base = "C(offer_type, Treatment('{0}'))".format(base_category)

    # construtio of the formula for the model
    join_string =[" + ", ":{0} + "][interaction * 1]
    formula = join_string.join(model_vars)

    if interaction:
        formula += ":{0}"

    else:
        formula = "{0} + " + formula

    formula = formula.format(offer_base)

    # inclusion of dependent and offer_type to create train and tests sets
    model_data = offers[["completed"] + ["offer_type"] + model_vars]

    train, val = train_test_split(model_data, test_size=0.2, random_state=123)

    # obtaining data for the model from formulas
    y_train = train["completed"]
    X_train = train.drop("completed", axis=1)

    y_val = val["completed"]
    X_val = val.drop("completed", axis=1)

    exog_train = patsy.dmatrix(formula, data=X_train)
    exog_val = patsy.dmatrix(formula, data=X_val)

    # fit model
    lg = sm.Logit(endog=y_train, exog=exog_train)
    result = lg.fit()

    return result, formula, exog_train, exog_val, X_val, y_val


def model_outcome(result, exog_val, y_val):
    '''Prints the outcome of the model based on the predictions in a validation set

    INPUTS

    - results: fitted regression model generated by fit_logistic
    - exog_val: DesignMatrix from the patsy package with the data form the independent variables
    - y_val: array for the "completed" variable, our dependent variable in the model

    RETURNS

    (none): the function prints the output in the form of a confusion matrix and the precision, recall and F score
    '''

    y_val_pred = (result.predict(exog_val) > 0.5).astype(int)
    accuracy = (y_val == y_val_pred).mean()

    print("Accuracy: ", accuracy)
    print("")
    print("Confusion matrix")
    print(confusion_matrix(y_val, y_val_pred))
    print("")
    print("Scoring")
    print(classification_report(y_val, y_val_pred, digits=2))

